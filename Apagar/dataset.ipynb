{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processando a imagem!\n",
    "def process(img):\n",
    "     # convercao de RGB para BGR e grayscale\n",
    "     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "     # aplicando o filtro gaussiano \n",
    "     img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "     # detectando as bordas\n",
    "     img_canny = cv2.Canny(img_blur, 100, 200)\n",
    "     # retorna um array com o tamanho (9,9 (?)) preenchido com 1\n",
    "     kernel = np.ones((9, 9))\n",
    "     # dilatando a imagem\n",
    "     img_dilate = cv2.dilate(img_canny, kernel, iterations=1)\n",
    "     # kernel = np.ones((5,5))\n",
    "     # erodindo a imagem\n",
    "     return cv2.erode(img_dilate, kernel, iterations=1)\n",
    "\n",
    "def process_symbols(img):\n",
    "     kernel = np.ones((3, 3))\n",
    "     img_erode =  cv2.erode(img, kernel, iterations=1)\n",
    "     img_dilate = cv2.dilate(img_erode, kernel, iterations=1)\n",
    "     return img_dilate\n",
    "\n",
    "# achando os contornos!\n",
    "def convex_hull(cnt):\n",
    "     # distancia maxima do contorno pra um contorno aproximado, eh o que garante um bom contorno (eh um parametro de precisao)\n",
    "     # calcula o perimetor do contorno!\n",
    "     epsilon = cv2.arcLength(cnt, True)\n",
    "     # aproximacao dos poligonos com a precisao do epsilon\n",
    "     approx = cv2.approxPolyDP(cnt, epsilon * 0.02, True)\n",
    "     # corrige uma \"curva\" defeituosa do contorno\n",
    "     return cv2.convexHull(approx).squeeze()\n",
    "\n",
    "# recebe\n",
    "def get_square_corners_v2(contours):\n",
    "     flag = 0 \n",
    "     for contour in contours:\n",
    "          if len(contour)<4:\n",
    "               continue\n",
    "          inner = contour\n",
    "          ordenando_indice_x = inner[...,0].argsort()\n",
    "          ordenando_x_menor = sorted(inner[ordenando_indice_x], key=itemgetter(0))\n",
    "\n",
    "          lista_x_menor = np.array(ordenando_x_menor[0:2])\n",
    "          lista_x_maior = np.array(ordenando_x_menor[2:])\n",
    "\n",
    "          ordenando_indice_y_menor = lista_x_menor[...,1].argsort()\n",
    "          top_lef_inner, bot_lef_inner = sorted(lista_x_menor[ordenando_indice_y_menor], key=itemgetter(1))\n",
    "\n",
    "          ordenando_indice_y_maior = lista_x_maior[...,1].argsort()\n",
    "          top_rit_inner, bot_rit_inner = sorted(lista_x_maior[ordenando_indice_y_maior], key=itemgetter(1))\n",
    "\n",
    "          dist = np.linalg.norm(top_rit_inner - top_lef_inner)\n",
    "          if dist > 100:\n",
    "               flag = True\n",
    "               break\n",
    "     \n",
    "     if not flag:\n",
    "          return None\n",
    "               \n",
    "     p2 = 2*top_lef_inner - bot_lef_inner\n",
    "     p5 = 2*top_lef_inner - top_rit_inner\n",
    "     p3 = 2*top_rit_inner - bot_rit_inner\n",
    "     p6 = 2*top_rit_inner - top_lef_inner\n",
    "     p7 = 2*bot_lef_inner - bot_rit_inner\n",
    "     p10 = 2*bot_lef_inner - top_lef_inner\n",
    "     p8 = 2*bot_rit_inner - bot_lef_inner\n",
    "     p11 = 2*bot_rit_inner - top_rit_inner\n",
    "     p1 = 2*top_lef_inner - bot_rit_inner\n",
    "     p4 = 2*top_rit_inner - bot_lef_inner\n",
    "     p9 = 2*bot_lef_inner - top_rit_inner\n",
    "     p12 = 2*bot_rit_inner - top_lef_inner\n",
    "\n",
    "     return [[p1,p2,top_lef_inner,p5],[p2,p3,top_rit_inner,top_lef_inner],[p3,p4,p6,top_rit_inner],[p5,top_lef_inner,bot_lef_inner,p7],[top_lef_inner,top_rit_inner,bot_rit_inner,bot_lef_inner],[top_rit_inner,p6,p8,bot_rit_inner],[p7,bot_lef_inner,p10,p9],[bot_lef_inner,bot_rit_inner,p11,p10],[bot_rit_inner,p8,p12,p11]]\n",
    "     \n",
    "def get_square_corners(inner, outer): \n",
    "\n",
    "     ordenando_indice_x = inner[...,0].argsort()\n",
    "     ordenando_x_menor = sorted(inner[ordenando_indice_x], key=itemgetter(0))\n",
    "\n",
    "     lista_x_menor = np.array(ordenando_x_menor[0:2])\n",
    "     lista_x_maior = np.array(ordenando_x_menor[2:])\n",
    "\n",
    "     ordenando_indice_y_menor = lista_x_menor[...,1].argsort()\n",
    "     top_lef_inner, bot_lef_inner = sorted(lista_x_menor[ordenando_indice_y_menor], key=itemgetter(1))\n",
    "     \n",
    "     ordenando_indice_y_maior = lista_x_maior[...,1].argsort()\n",
    "     top_rit_inner, bot_rit_inner = sorted(lista_x_maior[ordenando_indice_y_maior], key=itemgetter(1))\n",
    "\n",
    "     # pegando todas as linhas e coluna 0, e fazendo um sort com os indices (da coluna do eixo X)! (ordem crescente)\n",
    "     sort_outer_index_x0 = outer[..., 0].argsort()\n",
    "     # pegando todas as linhas e coluna 1, e fazendo um sort com os indices (da coluna do eixo Y)! (ordem crescente)\n",
    "     sort_outer_index_y1 = outer[..., 1].argsort()\n",
    "\n",
    "     # definindo os pontos laterais\n",
    "     ordenando_x_menor = sorted(outer[sort_outer_index_x0], key=itemgetter(0))\n",
    "     ordenando_y_menor = sorted(outer[sort_outer_index_y1], key=itemgetter(1))\n",
    "\n",
    "     lista_x_menor = np.array(ordenando_x_menor[0:2])\n",
    "     lista_x_maior = np.array(ordenando_x_menor[6:])\n",
    "\n",
    "     ordenando_indice_y_menor = lista_x_menor[...,1].argsort()\n",
    "\n",
    "     left_top_outer, left_bot_outer = sorted(lista_x_menor[ordenando_indice_y_menor], key=itemgetter(1))\n",
    "     \n",
    "     ordenando_indice_y_maior = lista_x_maior[...,1].argsort()\n",
    "     rig_top_outer, rig_bot_outer = sorted(lista_x_maior[ordenando_indice_y_maior], key=itemgetter(1))\n",
    "\n",
    "     # definindo\n",
    "     lista_y_menor = np.array(ordenando_y_menor[0:2])\n",
    "     lista_y_maior = np.array(ordenando_y_menor[6:])\n",
    "\n",
    "     ordenando_indice_x_menor = lista_y_menor[...,1].argsort()\n",
    "     top_left_outer, top_rit_outer = sorted(lista_y_menor[ordenando_indice_x_menor], key=itemgetter(0))\n",
    "     \n",
    "     ordenando_indice_x_maior = lista_y_maior[...,1].argsort()\n",
    "     bot_left_outer, bot_rit_outer = sorted(lista_y_maior[ordenando_indice_x_maior], key=itemgetter(0))\n",
    "\n",
    "\n",
    "     # calculando os pontos que nao temos\n",
    "     top_left_zero = top_left_outer + left_top_outer - top_lef_inner \n",
    "     bot_left_zero = bot_left_outer + left_bot_outer - bot_lef_inner\n",
    "     top_rit_zero = top_rit_outer + rig_top_outer - top_rit_inner\n",
    "     bot_rit_zero = bot_rit_outer + rig_bot_outer - bot_rit_inner\n",
    "     # yield np.mean ([bot_rit_outer],0)\n",
    "\n",
    "     # yield np.mean ([top_left_zero],0)\n",
    "     # yield np.mean ([top_lef_inner],0)\n",
    "     # yield np.mean ([left_top_outer],0)\n",
    "\n",
    "     quadrado_11 = [top_left_zero, top_left_outer, top_lef_inner, left_top_outer]\n",
    "     quadrado_12 = [top_left_outer, top_rit_outer, top_rit_inner, top_lef_inner]\n",
    "     quadrado_13 = [top_rit_outer, top_rit_zero, rig_top_outer, top_rit_inner]\n",
    "     quadrado_21 = [left_top_outer, top_lef_inner, bot_lef_inner, left_bot_outer]\n",
    "     quadrado_22 = [top_lef_inner, top_rit_inner, bot_rit_inner, bot_lef_inner]\n",
    "     quadrado_23 = [top_rit_inner, rig_top_outer, rig_bot_outer, bot_rit_inner]\n",
    "     quadrado_31 = [left_bot_outer, bot_lef_inner, bot_left_outer, bot_left_zero]\n",
    "     quadrado_32 = [bot_lef_inner, bot_rit_inner, bot_rit_outer, bot_left_outer]\n",
    "     quadrado_33 = [bot_rit_inner, rig_bot_outer, bot_rit_zero, bot_rit_outer]\n",
    "\n",
    "     # yield np.mean(quadrado_11,0)\n",
    "     # yield np.mean(quadrado_12,0)\n",
    "     # yield np.mean(quadrado_13,0)\n",
    "     # yield np.mean(quadrado_21,0)\n",
    "     # yield np.mean(quadrado_22,0)\n",
    "     # yield np.mean(quadrado_23,0)\n",
    "     # yield np.mean(quadrado_31,0)\n",
    "     # yield np.mean(quadrado_32,0)\n",
    "     # yield np.mean(quadrado_33,0)\n",
    "\n",
    "     quadrados = [quadrado_11, quadrado_12, quadrado_13, quadrado_21, quadrado_22, quadrado_23, quadrado_31, quadrado_32, quadrado_33]\n",
    "\n",
    "     return quadrados\n",
    "\n",
    "# recebe os 4 vertices para cortar na imagem      \n",
    "def get_squares_init(pontos_quadrado):\n",
    "\n",
    "     # https://stackoverflow.com/questions/48301186/cropping-concave-polygon-from-image-using-opencv-python\n",
    "\n",
    "     # criando um retangulo com os vertices\n",
    "     rect_corte = cv2.boundingRect(pontos_quadrado)\n",
    "     # passando as coordenadas para as variaveis\n",
    "     x,y,w,h = rect_corte\n",
    "     # cortando a imagem com as variaveis\n",
    "     croped = img_processada[y:y+h, x:x+w].copy()\n",
    "\n",
    "     # fazendo mascara para o corte da imagem\n",
    "     pontos_quadrado = pontos_quadrado - pontos_quadrado.min(axis=0)\n",
    "     mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "     # desenhando os contornos usando a mascara\n",
    "     cv2.drawContours(mask, [pontos_quadrado], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "     # fazendo comparacao da imagem cortada com a mascara\n",
    "     croped_image_final = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "     return croped_image_final\n",
    "     # cv2.imshow(\"final\",croped_image_final)\n",
    "     # cv2.waitKey(0)\n",
    "     \n",
    "def get_squares_after_play(pontos_quadrado, img):\n",
    "\n",
    "     # https://stackoverflow.com/questions/48301186/cropping-concave-polygon-from-image-using-opencv-python\n",
    "\n",
    "     # criando um retangulo com os vertices\n",
    "     rect_corte = cv2.boundingRect(pontos_quadrado)\n",
    "     # passando as coordenadas para as variaveis\n",
    "     x,y,w,h = rect_corte\n",
    "     # cortando a imagem com as variaveis\n",
    "     croped = img[y:y+h, x:x+w].copy()\n",
    "\n",
    "     # fazendo mascara para o corte da imagem\n",
    "     pontos_quadrado = pontos_quadrado - pontos_quadrado.min(axis=0)\n",
    "     mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "     # desenhando os contornos usando a mascara\n",
    "     cv2.drawContours(mask, [pontos_quadrado], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "     # fazendo comparacao da imagem cortada com a mascara\n",
    "     croped_image_final = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "     return croped_image_final\n",
    "     # cv2.imshow(\"final\",croped_image_final)\n",
    "     # cv2.waitKey(0)\n",
    "        \n",
    "# recebe a imagem sem filtrar (imagem original dos quadrados com os simbolos)\n",
    "def get_circles(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    gray_blurred = cv2.blur(gray, (3, 3)) \n",
    "    \n",
    "    # Apply Hough transform on the blurred image. \n",
    "    detected_circles = cv2.HoughCircles(gray_blurred,  \n",
    "                    cv2.HOUGH_GRADIENT, 1, 20, param1 = 50, \n",
    "                param2 = 30, minRadius = 1, maxRadius = 40) \n",
    "    \n",
    "    # desenhando os circulos detectados (precisamos desenhar msm, n eh soh pegar se tem ou n?)\n",
    "    if detected_circles is not None: \n",
    "    # Convert the circle parameters a, b and r to integers. \n",
    "        detected_circles = np.uint16(np.around(detected_circles)) \n",
    "    \n",
    "        for pt in detected_circles[0, :]: \n",
    "            a, b, r = pt[0], pt[1], pt[2] \n",
    "    \n",
    "            # Draw the circumference of the circle. \n",
    "            cv2.circle(img, (a, b), r, (0, 255, 0), 2) \n",
    "    \n",
    "            # Draw a small circle (of radius 1) to show the center. \n",
    "            cv2.circle(img, (a, b), 1, (0, 0, 255), 3) \n",
    "            cv2.imshow(\"Detected Circle\", img) \n",
    "            \n",
    "            cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria do Dataset de CÃ­rculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_image = 0\n",
    "defective_images = []\n",
    "for f in range(1,20):\n",
    "     img = cv2.imread(f\"Webcam/O/TabuleiroO{f}.jpg\")\n",
    "     img_processada = process(img)\n",
    "     contours, _ = cv2.findContours(img_processada, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE) #talvez usar o CHAIN_APPROX_SIMPLE, ver a diferenca em https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html\n",
    "     aux = sorted(map(convex_hull, contours), key=len)\n",
    "     lista_quadrados = get_square_corners_v2(aux)\n",
    "     \n",
    "     for file in os.listdir('Webcam/O/'):\n",
    "          if file.find(f'O{f}-') != -1:\n",
    "               img_x = cv2.imread(os.path.join('Webcam/O',file))\n",
    "               img_processada_x = process(img_x)\n",
    "\n",
    "               template = img_processada\n",
    "\n",
    "               # Template Matching to Detect Pattern\n",
    "               result = cv2.matchTemplate(img_processada_x, template, cv2.TM_CCOEFF_NORMED)\n",
    "               min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "               dx = int(max_loc[0] - max_loc[0])\n",
    "               dy = int(max_loc[1] - max_loc[1])\n",
    "\n",
    "               rows, cols = img_processada_x.shape\n",
    "               M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "               aligned_image2 = cv2.warpAffine(img_processada_x, M, (cols, rows))\n",
    "\n",
    "               # Subtract Images\n",
    "               img_sub_processada = cv2.subtract(aligned_image2, img_processada)\n",
    "               #img_sub = cv2.subtract(img_processada_x, img_processada)\n",
    "\n",
    "               #img_sub_processada = process_symbols(img_sub)\n",
    "\n",
    "               square = lista_quadrados[4]\n",
    "               teste = np.array([[ponto[0],ponto[1]] for ponto in square])\n",
    "               teste = teste.reshape((-1, 1, 2))\n",
    "               cv2.polylines(img_sub_processada,[teste], True, (255, 0, 0), 2)\n",
    "               cv2.imwrite(f\"dataset/teste/primeira_subtraida_processada{file}.jpg\", img_sub_processada)\n",
    "               cv2.imwrite(f\"dataset/teste/primeira_subtraida_processada2{file}.jpg\", img)\n",
    "               \n",
    "               if lista_quadrados is None:\n",
    "                    raise(\"Deu Ruim\")\n",
    "               #try:\n",
    "               #     # pegando os contornos internos (quadrado do meio) e externos\n",
    "               #     inner, outer = sorted(map(convex_hull, contours), key=len)\n",
    "               #except:\n",
    "               #     if f\"Webcam/O/TabuleiroO{i}.jpg\" not in defective_images:\n",
    "               #          defective_images.append(f\"Webcam/O/TabuleiroO{i}.jpg\")\n",
    "               #     continue\n",
    "               # usando os contornos para calcular as coordenadas dos quadrados da matriz\n",
    "\n",
    "               for i in range(0,9):\n",
    "                    lista_imagens_cortadas = get_squares_init(np.array(lista_quadrados[i]))\n",
    "                    cv2.imwrite(f\"dataset/empty/o{index_image}.png\",lista_imagens_cortadas)\n",
    "                    imagem_cortada_com_x_tratada = get_squares_after_play(np.array(lista_quadrados[i]), img_sub_processada)\n",
    "                    cv2.imwrite(f\"dataset/o/o{index_image}.png\",imagem_cortada_com_x_tratada)\n",
    "                    index_image += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defective_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_image = 0\n",
    "defective_images = []\n",
    "for f in range(1,14):\n",
    "     img = cv2.imread(f\"Webcam/X/TabuleiroX{f}.jpg\")\n",
    "     img_processada = process(img)\n",
    "     contours, _ = cv2.findContours(img_processada, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE) #talvez usar o CHAIN_APPROX_SIMPLE, ver a diferenca em https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html\n",
    "     aux = sorted(map(convex_hull, contours), key=len)\n",
    "          \n",
    "     lista_quadrados = get_square_corners_v2(aux)\n",
    "     #for square in lista_quadrados:\n",
    "     #square = lista_quadrados[4]\n",
    "     #teste = np.array([[ponto[0],ponto[1]] for ponto in square])\n",
    "     #teste = teste.reshape((-1, 1, 2))\n",
    "     #cv2.polylines(img_sub_processada,[teste], True, (255, 0, 0), 2)\n",
    "     #cv2.imwrite(f\"dataset/teste/primeira_subtraida_processada{file}.jpg\", img_sub_processada)\n",
    "     #cv2.imwrite(f\"dataset/teste/primeira_subtraida_processada2{file}.jpg\", img)\n",
    "     for file in os.listdir('Webcam/X/'):\n",
    "          if file.find(f'X{f}-') != -1:\n",
    "               img_x = cv2.imread(os.path.join('Webcam/X',file))\n",
    "               img_processada_x = process(img_x)\n",
    "\n",
    "               template = img_processada\n",
    "\n",
    "               # Template Matching to Detect Pattern\n",
    "               result = cv2.matchTemplate(img_processada_x, template, cv2.TM_CCOEFF_NORMED)\n",
    "               min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "               dx = int(max_loc[0] - max_loc[0])\n",
    "               dy = int(max_loc[1] - max_loc[1])\n",
    "\n",
    "               rows, cols = img_processada_x.shape\n",
    "               M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "               aligned_image2 = cv2.warpAffine(img_processada_x, M, (cols, rows))\n",
    "\n",
    "               # Subtract Images\n",
    "               img_sub_processada = cv2.subtract(aligned_image2, img_processada)\n",
    "\n",
    "               #img_sub = cv2.subtract(img_processada_x, img_processada)\n",
    "\n",
    "               #img_sub_processada = process_symbols(img_sub)\n",
    "               #cv2.imwrite(f\"dataset/teste/primeira_subtraida_processada{file}.jpg\", img_processada)\n",
    "               \n",
    "               if lista_quadrados is None:\n",
    "                    raise(\"Deu Ruim\")\n",
    "               for i in range(0,9):\n",
    "                    lista_imagens_cortadas = get_squares_init(np.array(lista_quadrados[i]))\n",
    "                    cv2.imwrite(f\"dataset/empty/x{index_image}.png\",lista_imagens_cortadas)\n",
    "                    imagem_cortada_com_x_tratada = get_squares_after_play(np.array(lista_quadrados[i]), img_sub_processada)\n",
    "                    cv2.imwrite(f\"dataset/x/x{index_image}.png\",imagem_cortada_com_x_tratada)\n",
    "                    index_image += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\FSFKD\\Documents\\Faculdade\\Oficinas 2\\ImageClassification\\Oficinas2-main\\dataset.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m20\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m      img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWebcam/X/TabuleiroO\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m      img_processada \u001b[39m=\u001b[39m process(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m      \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39mWebcam/O/\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m           \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\FSFKD\\Documents\\Faculdade\\Oficinas 2\\ImageClassification\\Oficinas2-main\\dataset.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(img):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m      \u001b[39m# convercao de RGB para BGR e grayscale\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m      img_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m      \u001b[39m# aplicando o filtro gaussiano \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FSFKD/Documents/Faculdade/Oficinas%202/ImageClassification/Oficinas2-main/dataset.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m      img_blur \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mGaussianBlur(img_gray, (\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m), \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "index_image = 0\n",
    "defective_images = []\n",
    "for i in range(1,20):\n",
    "     img = cv2.imread(f\"Webcam/X/TabuleiroO{i}.jpg\")\n",
    "     img_processada = process(img)\n",
    "     for file in os.listdir('Webcam/O/'):\n",
    "          if file.find(f'O{i}-') != -1:\n",
    "               img_x = cv2.imread(os.path.join('Webcam/O',file))\n",
    "               img_processada_x = process(img_x)\n",
    "\n",
    "               img_sub = cv2.subtract(img_processada_x, img_processada)\n",
    "\n",
    "               img_sub_processada = process_symbols(img_sub)\n",
    "\n",
    "               contours, _ = cv2.findContours(img_processada, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE) #talvez usar o CHAIN_APPROX_SIMPLE, ver a diferenca em https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html\n",
    "               try:\n",
    "                    # pegando os contornos internos (quadrado do meio) e externos\n",
    "                    inner, outer = sorted(map(convex_hull, contours), key=len)\n",
    "               except:\n",
    "                    if f\"Webcam/O/TabuleiroO{i}.jpg\" not in defective_images:\n",
    "                         defective_images.append(f\"Webcam/O/TabuleiroO{i}.jpg\")\n",
    "                    continue\n",
    "               # usando os contornos para calcular as coordenadas dos quadrados da matriz\n",
    "               lista_quadrados = get_square_corners(inner,outer)\n",
    "\n",
    "               for i in range(0,9):\n",
    "                    k=i+1\n",
    "                    if(k%3==0):\n",
    "                         j=3\n",
    "                    else:\n",
    "                         j=k%3\n",
    "                    k=int(i/3)+1\n",
    "                    lista_imagens_cortadas = get_squares_init(np.array(lista_quadrados[i]))\n",
    "                    cv2.imwrite(f\"dataset/empty/b{index_image}.png\",lista_imagens_cortadas)\n",
    "                    imagem_cortada_com_x_tratada = get_squares_after_play(np.array(lista_quadrados[i]), img_sub_processada)\n",
    "                    cv2.imwrite(f\"dataset/o/o{index_image}.png\",imagem_cortada_com_x_tratada)\n",
    "                    if index_image == 161:\n",
    "                         pass\n",
    "                    index_image += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defective_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
